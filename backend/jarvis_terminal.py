
from jarvis_voice import parler_en_jarvis
from jarvis_scan import scanner_bouteille
from jarvis_wine import ajouter_bouteille_depuis_scan, ajouter_bouteille_en_base
from jarvis_wine import interpreter_ajout_vocal  # Ã  importer en haut
from jarvis_utils import detecte_commande

from mistralai import Mistral
from dotenv import load_dotenv
import os
from vosk import Model, KaldiRecognizer
import pyttsx3
import json
import wave
import pyaudio
import cv2


load_dotenv()
client_mistral = Mistral(api_key=os.getenv("MISTRAL_API_KEY"))

# === ğŸ§ Configuration Vosk ===
MODEL_PATH = "C:/Users/cyril/OneDrive/Documents/Projet_assistants_IA/jarvis-IA/backend/vosk-model-small-fr-0.22"
USE_VOICE_RESPONSE = True

if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"ModÃ¨le Vosk non trouvÃ© Ã  l'emplacement : {MODEL_PATH}")

vosk_model = Model(MODEL_PATH)
recognizer = KaldiRecognizer(vosk_model, 16000)

# === ğŸ”Š SynthÃ¨se vocale ===
engine = pyttsx3.init()
engine.setProperty('rate', 160)
if os.name == 'posix':
    engine.setProperty('voice', 'com.apple.speech.synthesis.voice.thomas')

mode_concise = True  # Active au dÃ©marrage


# === ğŸ¤ Enregistrement audio ===
def record_audio(filename="output.wav", duration=5):
    p = pyaudio.PyAudio()
    stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)
    print("ğŸ™ï¸ Parle maintenant...")
  # frames = [stream.read(4000) for _ in range(0, int(16000 / 8000 * duration))]
    frames = [stream.read(8000) for _ in range(0, int(16000 / 8000 * duration))]

   
    stream.stop_stream()
    stream.close()
    p.terminate()

    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
        wf.setframerate(16000)
        wf.writeframes(b''.join(frames))

    print("âœ… Enregistrement terminÃ©.")
    return filename

# === ğŸ§  Reconnaissance vocale ===
def recognize(filename):
    with wave.open(filename, 'rb') as wf:
        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000:
            raise ValueError("Audio non conforme : 1 canal, 16 bits, 16000 Hz requis.")

        recognizer = KaldiRecognizer(vosk_model, wf.getframerate())
        recognizer.SetWords(True)

        text = ""
        while True:
            data = wf.readframes(4000)
            if not data:
                break
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text += result.get("text", "") + " "

        final_result = json.loads(recognizer.FinalResult())
        text += final_result.get("text", "")
        return text.strip()

def jarvis_repond(prompt: str, mode_concise=False,interruption_active=False):
    if mode_concise:
        prompt = f"RÃ©ponds de faÃ§on brÃ¨ve, directe, sans suggestions : {prompt}"

    
    response = client_mistral.chat.complete(
        model="mistral-small-latest",
        messages=[{"role": "user", "content": prompt}]
    )
    texte = response.choices[0].message.content
    print(f"ğŸ§  Jarvis dit : {texte}")
    parler_en_jarvis(texte,interruption_active=interruption_active)


def gestion_scan_bouteille():
    texte_ocr = scanner_bouteille()
    if not texte_ocr:
        print("Pas de text OCR de scannÃ©")
        return

    data_bouteille = ajouter_bouteille_depuis_scan(texte_ocr)
    print("\nğŸ†• DÃ©tails dÃ©tectÃ©s :")
    print(f"Nom          : {data_bouteille['nom']}")
    print(f"AnnÃ©e        : {data_bouteille['annÃ©e']}")
    print(f"Type         : {data_bouteille['type']}")
    print(f"Texte brut   : {data_bouteille['texte_detectÃ©']}")

    # ğŸ’¬ Menu terminal (bouton simulÃ©)
    print("\nğŸ’¡ Voulez-vous ajouter cette bouteille Ã  la cave ?")
    print("[1] âœ… Oui, ajouter")
    print("[2] âŒ Non, ignorer")

    choix = input("ğŸ‘‰ Votre choix : ")
    if choix == "1":
        ajouter_bouteille_en_base(data_bouteille)
        print("ğŸ“¦ Bouteille ajoutÃ©e avec succÃ¨s dans la cave.")
    else:
        print("â¹ï¸ Bouteille ignorÃ©e.")





# === ğŸ” Boucle principale ===
if __name__ == "__main__":
   """
    #Test de capture video 
    cap = cv2.VideoCapture(0)
    ret, frame = cap.read()
    print("Fonctionne ?", ret)
    cap.release()

    gestion_scan_bouteille()  # test direct
    """
   interruption_active = False  # ğŸ›‘ Interruption dÃ©sactivÃ©e par dÃ©faut
      
while True:
       
        input("ğŸŸ¢ Appuie sur EntrÃ©e pour parler Ã  Jarvis (ou Ctrl+C pour quitter)...")
        file = record_audio(duration=5)
        recognized = recognize(file)

        if not recognized:
            print("âŒ Rien reconnu. RÃ©essaie.")
            continue

        print(f"ğŸ—£ï¸ Tu as dit : {recognized}")
 
        # ğŸ“· Commande de scan
        commande = detecte_commande(recognized)
        print(f"ğŸ” Commande dÃ©tectÃ©e : {commande}")
        if commande == "stop":
                interruption_active = True
                print("â›” Interruption activÃ©e")
                parler_en_jarvis("D'accord, j'arrÃªte la rÃ©ponse.")
                continue

        if interruption_active:
                print("ğŸ¤ Mode silencieux actif â€” Jarvis ne rÃ©pondra pas.")
                continue

        if commande == "ajout d'une bouteille":
            print("ğŸ“¸ Scanner lancÃ©")
            gestion_scan_bouteille()
            continue
        elif commande == "liste":
            print("ğŸ“¦ Affichage de la cave")
            lister_bouteilles()
            continue

        elif commande == "retirer":
            print("ğŸ—‘ï¸ Retrait (fonction Ã  implÃ©menter)")
            # Tu peux appeler une fonction comme retirer_bouteille_vocalement(recognized)
            continue
        else:
            # ğŸ§  RÃ©ponse gÃ©nÃ©rale de Jarvis
            prompt = f"RÃ©ponds briÃ¨vement : {recognized}" if mode_concise else recognized
            jarvis_repond(prompt,mode_concise=mode_concise, interruption_active=interruption_active)
            continue

       


        
    
        


